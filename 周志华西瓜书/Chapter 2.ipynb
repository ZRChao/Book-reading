{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二章 模型评估与选择 2019-5-12\n",
    "\n",
    "### 经验误差与过拟合\n",
    "\n",
    "- [**错误率**](#t1) 分类错误的样本占总样本的比例； **精度** = 1 - 错误率\n",
    "\n",
    "- 训练误差/经验误差 在训练集上的误差：预测输出与真实输出的差异\n",
    "\n",
    "- **泛化误差**generalization error，在新样本上的误差，也就是极小化的目标函数，希望在训练样本中学到所有样本的‘普遍规律’，无法直接获取。\n",
    "    - overfitting,<u>学习能力过强</u> 而过度以至于把训练样本自身的特点当做了所有潜在样本都会具有的一般性质，从而导致泛化性能降低；机器学习的关键障碍，无法彻底避免需尽可能的缓解: $P\\neq NP$\n",
    "    - underfitting，对训练样本的一般性尚未学好。\n",
    "\n",
    "- 模型选择 model selection，目标是评估候选模型的泛化误差，并选择最小的。\n",
    "\n",
    "\n",
    "### 评估方法\n",
    "\n",
    "以测试集上的测试误差test error 作为泛化误差的近似。测试集合需要与训练集互斥--不重合。\n",
    "\n",
    "#### 留出法 hold-out\n",
    "\n",
    "将数据集拆分使满足 $D=S\\cup T, S\\cap T = \\emptyset$，但是要保证S与T分布的一致性，如分类问题中的样本均衡（采用分层抽样），以此避免引入额外的偏差。\n",
    "\n",
    " - 稳定性：多次随机划分取平均\n",
    " - 保真性 fidelity：S太大，导致T上评估结果不够稳定；S太小，评估模型与D差别太大， 2/3~4/5 用于训练\n",
    " \n",
    "#### 交叉验证 cross validation CV\n",
    "\n",
    "**k-折交叉验证**，将数据D划分k个大小相似的互斥子集，通常取（5，10，20等），依次去掉一折训练之然后在该折上测试。避免划分不同映入的误差，类似于留出法重复多次。如10次10折交叉验证，100次留出法都进行了100次训练/测试。\n",
    "\n",
    " - 留一法 Leave-One-Out/LOO, m个样本，则k=m，虽然不受划分的影响，结果比较准确，但是计算量大。并且根据NFL原理，也未必永远好过其他方法。\n",
    " \n",
    "#### 自助法 bootstrapping\n",
    " \n",
    " - 进行有放回的随机采样构造与D一样大小的抽样集合D', $\\lim\\limits_{m\\to+\\infty}(1-\\frac{1}{m})^m \\to \\frac{1}{e} \\approx 0.368$,为此总体上大约1/3的样本没有出现在训练集中，用该集合进行测试--**包外估计** out-of-bag-estimate。\n",
    " \n",
    "留出法与交叉验证都保留了测试集，而未使用所有的D，必然引入一些因训练样本规模不同而导致的估计偏差。但是自助法改变了初始数据的分布而引入估计偏差，故在数据量足够时，留出法与交叉验证更常用。\n",
    "\n",
    "#### 调参与最终模型 parameter tuning\n",
    "\n",
    "估计所有参数空间的可能的模型是不切实际的，如深度学习中上百亿个参数。\n",
    "\n",
    " - 验证集 validation set,在模型评估与选择中的测试数据\n",
    " - 训练集，在模型选择完后，合并训练集与验证集一起估计参数\n",
    " - 测试集，实际中遇到的数据，新的数据集，用来判断算法的泛化能力\n",
    " \n",
    "\n",
    "### 性能度量 performance measure\n",
    "\n",
    "**均方误差** mean square error MSE\n",
    "\n",
    "#### <a id=t1>错误率与精度</a>\n",
    "\n",
    "#### [查准率Precision、查全率Recall与F1](https://www.jianshu.com/p/c61ae11cc5f6)\n",
    "\n",
    "| |预测为真|预测为假|\n",
    "|---|\n",
    "|真|TP（真正例）|FN（假反例）|\n",
    "|假|FP（假正例）|TN（真反例）|\n",
    "\n",
    "$$查准率P/precision = \\frac{TP}{TP+FP}$$\n",
    "$$查全率R/recall召回率/TPR/灵敏度Sensitivity = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "$$FPR=\\frac{FP}{FP+TN}$$\n",
    "\n",
    "两者一般互斥，综合来看进行\n",
    " - 排序，画出**P-R**曲线，比较曲线下的面积\n",
    " - 平衡点 Break-Event Point BEP， P=R时的取值\n",
    " - $F1=\\frac{2\\times P\\times R} {P+R}$，或者一般形式$F_\\beta, 2.11$\n",
    " \n",
    "当多次训练/测试可以得到多个二分类混淆矩阵\n",
    "\n",
    " - 宏查准率macro-P，宏查全率macro-R，及宏F1 macro-F1,计算平均P，R\n",
    " - 微查准率micro-P，微查全率micro-R，及微F1 micro-F1,计算平均TP，FP等在计算\n",
    "\n",
    "#### [ROC与AUC](https://www.jianshu.com/p/c61ae11cc5f6)\n",
    "\n",
    "ROC曲线的构造及其意义\n",
    "AUC的构造及其意义\n",
    "\n",
    "#### 代价敏感错误率与代价曲线\n",
    "\n",
    "因为不同类型的错误会造成不同的后果，上述混淆矩阵只考虑了错误与否，为权衡不同错误导致的损失，赋予了’非均等代价‘ unequal cost (代价矩阵)。\n",
    "\n",
    "**代价敏感错误率** cost-sensitive\n",
    "\n",
    "$$E(f;D;cost)=\\frac{1}{m}(\\sum_{x\\in D^+} I(f(x)\\neq y)\\times cost_{01} \\\\\n",
    "+ \\sum_{x\\in D^-} I(f(x)\\neq y)\\times cost_{10}\n",
    "$$\n",
    "\n",
    "**代价曲线** cost curve, x-正概率代价，y-归一化代价 （2.24/2/25）\n",
    "将ROC曲线上的每个点对应到代价平面上的一条线段，给出（TPR,FPR），计算出FNR，然后画直线（0，FPR）到（1，FNR),线段下的面积即该条件下的期望总体代价。因为直线$y=(FNR-FPR)x+FPR$,将x=正例概率代价2.24带入即可得归一化代价2.25。\n",
    "\n",
    "### 比较检验\n",
    "\n",
    "比较不同算法之间的优良\n",
    "\n",
    " - 泛化性能的比较不等价与测试集上的\n",
    " - 测试集上的性能依赖于测试集的选择与大小\n",
    " - 算法本身的随机性\n",
    " \n",
    "#### 假设检验--单个学习器的检验 $H_0: \\epsilon = \\epsilon_0$\n",
    "\n",
    " - 单次训练时：二项分布binomial，极大似然估计与理论临界值的比较\n",
    " - 多次训练时：t检验，平均测试错误率\n",
    " \n",
    "#### 交叉验证t检验 \n",
    "\n",
    "两个学习器之间的检验：成对t检验，实际上因为抽样的关系，测试错误率并不独立从而导致高估假设成立的概率。缓解策略：\n",
    "\n",
    "  - $5\\times 2$交叉验证，均值用第一次的，方差用五次平均值。\n",
    "\n",
    "#### [McNemar检验](https://everipedia.org/wiki/lang_en/McNemar%27s_test/)\n",
    "\n",
    "两个学习器之间的检验：**列联表** contingency table, 分类错误不一致的效果一样(算法的边际同质性状态应该一样)，使用条件 不一致的和超过25，否则使用精确binomial检验。\n",
    "\n",
    "#### Friedman和Nemenyi检验\n",
    "\n",
    "多个学习器之间的检验：\n",
    "\n",
    " 1. 算法比较序值表（各测试数据上不同算法优良排序的秩），构造原始的Friedman检验（卡方分布）或者修正的（F分布）\n",
    " 2. Nemenyi检验，当拒绝上一步后post-hoc test，比较各个算法之间的差值与临界值的大小。\n",
    " \n",
    "**Friedman检验图**，看是否有重叠。\n",
    "\n",
    "![](https://tse1-mm.cn.bing.net/th?id=OIP.xsy5BZfRguVxyBoyIow5zgFVC2&w=196&h=105&c=8&rs=1&qlt=90&dpr=2&pid=3.1&rm=2)\n",
    "\n",
    "\n",
    "### [偏差与方差 bias-variance decomposition](https://blog.csdn.net/pipisorry/article/details/50638749)\n",
    "\n",
    "噪声使得$y_D\\neq y$\n",
    "\n",
    "$$E(f;D)=(\\bar f-y)^2 + E_D(f-\\bar f)^2 + E_D(y_D-y)^2$$\n",
    "\n",
    "也就是说，泛化误差可分解为偏差，方差与噪声之和。其中偏差度量了学习算法的期望预测与真实结果的偏离程度，刻画了算法本身的拟合能力；方差则刻画数据扰动造成的影响；噪声表达了学习本身问题的难度，是期望泛化误差的下届。这说明泛化能力是由算法的能力，数据的充分性以及学习任务本身的难度共同决定的。\n",
    "\n",
    " - 偏差-方差窘境 bias-variance dilemma\n",
    "   - 偏差主导，在训练不足时拟合能力不够，模型对数据扰动不敏感\n",
    "   - 方差主导，训练的加强，拟合能力太强而训练数据的扰动被学习到，数据的轻微扰动都会导致学习器显著变化，很容易过拟合。\n",
    "   \n",
    "   \n",
    "### 阅读材料\n",
    "\n",
    " 1. ROC 的拓展及[多分类任务](https://blog.csdn.net/YE1215172385/article/details/79443552)\n",
    " 2. 代价曲线，不同的代价类型\n",
    " 3. 偏差-方差分解基于均方误差的回归任务，而对分类任务很困难。\n",
    " \n",
    "### 习题\n",
    "\n",
    "参考 https://blog.csdn.net/icefire_tyh/article/details/52065867\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
