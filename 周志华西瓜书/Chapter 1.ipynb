{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一章绪论 2019-5-11\n",
    "\n",
    "### 引言\n",
    "\n",
    "**<u>好瓜的条件判断</u>**\n",
    "\n",
    "机器学习，利用经验（数据）来对新的情况作出有效判断或是改善自身系统（模型）的性能。其主要内容即**学习算法**，从数据中产生模型。\n",
    "\n",
    "### 基本术语：\n",
    "- 示例/样本/特征向量 < 数据集， 训练样本 < 训练数据/训练集 + 测试样本\n",
    "- 属性/特征 ->属性空间/样本空间/输入空间， 标记空间/输出空间\n",
    "- 假设，学习该真相的模型为 学习器\n",
    "- 分类（二分类、多分类）/回归 -> 监督学习\n",
    "- 聚类 -> 无监督学习\n",
    "- 泛化能力（generalizaiton）训练集上训练的模型可以很好的适用馨的样本也即整个样本空间。\n",
    "\n",
    "### 假设空间\n",
    "\n",
    "归纳和演绎\n",
    "\n",
    "学习过程，可以看做一个在所有假设组成的空间中进行搜索来找到匹配的假设。有限样本可以造成多个假设与训练集一致，组成了假设集合--版本空间（version space）\n",
    "\n",
    "### 归纳偏好 inductive bias\n",
    "\n",
    "**对某种类型假设的偏好**，在庞大的假设空间中对假设进行选择的启发式。\n",
    "\n",
    "**奥卡姆剃刀，Occam's razor**, 最简单原则。--何为最简单？\n",
    "\n",
    "**没有免费的午餐 No Free Lunch, NFL**: <u>在所有模型服从均匀分布去的前提下</u>,无论某学习算法多聪明，但是他的性能和其他的是一样的。 [公式（1.1）](https://datawhalechina.github.io/pumpkin-book/#/chapter1/chapter1).\n",
    "\n",
    "谈论算法的优劣是需要结合具体问题进行具体分析的，学习算法自身的归纳偏好于问题是否匹配，往往会起到决定性的作用。\n",
    "\n",
    "### 发展历程\n",
    "\n",
    "- 二十世纪五十年代-七十年代初，人工智能’推理期’，逻辑理论家（A.Newell和H.Simon， 1975年图灵奖）\n",
    "- 二十世纪七十年代中期，‘知识期’，E.A.Feigenbaum 知识工程之父（1994年图灵奖）\n",
    "- 二十世纪八十年代，符号主义学习，如决策树等，但是由于学习假设空间太大，复杂度高\n",
    "- 二十世纪九十年代中前期，基于神经网络的连接主义学习，1986年D.E.Rumelhart发明的BP算法\n",
    "- 二十世纪九十年代中期，统计学习登场，SVM等核技术\n",
    "- 二十一世纪初，深度学习\n",
    "\n",
    "[来源](https://blogs.nvidia.com.tw/2016/07/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/)\n",
    "![](https://blogs.nvidia.com/wp-content/uploads/2016/07/Deep_Learning_Icons_R5_PNG.jpg.png)\n",
    "\n",
    "\n",
    "### 应用现状\n",
    "\n",
    "数据收集、存储、传输、处理能力的发展，\n",
    "\n",
    "- 搜索引擎\n",
    "- 无人驾驶\n",
    "- 奥巴马2012年大选\n",
    "\n",
    "### 阅读材料\n",
    "\n",
    "经典书籍\n",
    "- [The element of statistical learning. Hasite et al. 2009](https://web.stanford.edu/~hastie/Papers/ESLII.pdf) \n",
    "- [Pattern Recognition and Machine Learning. Bishop 2006](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/05/Bishop-PRML-sample.pdf)\n",
    "- 统计学习方法,李航 2007\n",
    "\n",
    "会议：\n",
    "[ICML](https://icml.cc/Conferences/2019), [NIPS](https://nips.cc/Conferences/2019)，[ACML](http://acml-conf.org/2019/)\n",
    "[中国机器学习大会 CCML](http://bdiri.gzu.edu.cn/ccml2019/)\n",
    "[中国机器学习及其应用研讨会 MLA](http://lamda.nju.edu.cn/conf/mla/)\n",
    "\n",
    "\n",
    "杂志：\n",
    "\n",
    "- *Journal of Machine Learning Research*, *Machine Learning*\n",
    "\n",
    "### 习题\n",
    "\n",
    "参考：[机器学习(周志华西瓜书) 参考答案 总目录](https://blog.csdn.net/icefire_tyh/article/details/52064910)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
